{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the MNIST dataset from sklearn.datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Break up the data into attributes and values\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_up(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    top = shifted_image[0,:]\n",
    "    for i in range(0, len(shifted_image)-1):\n",
    "        shifted_image[i,:] = shifted_image[i+1,:]  \n",
    "    shifted_image[27,:] = top\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "\n",
    "def shift_down(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    bottom = shifted_image[27,:]\n",
    "    for i in range(len(shifted_image)-1, 0,-1):\n",
    "        \n",
    "        shifted_image[i,:] = shifted_image[i-1,:]  \n",
    "    shifted_image[0,:] = bottom\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "def shift_left(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    left = shifted_image[:,0]\n",
    "    for i in range(0, len(shifted_image)-1):\n",
    "        shifted_image[:,i] = shifted_image[:,i+1]  \n",
    "    shifted_image[:,27] = left\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "def shift_right(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    right = shifted_image[:,27]\n",
    "    for i in range(len(shifted_image)-1, 0,-1):\n",
    "        \n",
    "        shifted_image[:,i] = shifted_image[:,i-1]  \n",
    "    shifted_image[:,0] = right\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(X)):\n",
    "\n",
    "    shifted_image_up = shift_up(X[i].copy())\n",
    "    shifted_image_down = shift_down(X[i].copy())\n",
    "    shifted_image_right = shift_right(X[i].copy())\n",
    "    shifted_image_left = shift_left(X[i].copy())\n",
    "\n",
    "    X = np.vstack((X, shifted_image_up))\n",
    "    X = np.vstack((X, shifted_image_down))\n",
    "    X = np.vstack((X, shifted_image_right))\n",
    "    X = np.vstack((X, shifted_image_left))\n",
    "    \n",
    "    yi = y[i]\n",
    "    \n",
    "    if(i % 1000 == 0):\n",
    "        print(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Break the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Shuffle up the data into X_train and y_train so that there is\n",
    "#No order to the values being observed\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'weights': ['uniform', 'distance'], 'n_neighbors': [1,2,4]}]\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
    "           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knn_clf, X = X_train, y = y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Show that the image at row 36000 is the value 5\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000,:]\n",
    "some_digit_image = some_digit.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGgCD8QFOEHgiL8QFD/DyNOA3YIyIH6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26144e3aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset\n",
    "\n",
    "\n",
    "# Columns we don't care about\n",
    "PassengerId, Name, Ticket, Cabin\n",
    "\n",
    "# Columns that we need to stratify on\n",
    "Survived\n",
    "\n",
    "# Columns that we do care about\n",
    "Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "# Categorical columns that we care about\n",
    "Survived, Pclass, Sex, Embarked\n",
    "\n",
    "# Numerical columns that we care about\n",
    "Age, SibSp, Parch, Fare\n",
    "\n",
    "# Additional Thoughts\n",
    "Break the classes up into newly made columns representing one for if they were in that class\n",
    "\n",
    "Stratify on survived and died to get an equal distribution on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fetch_data(path, csv_file):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"Titanic\")\n",
    "CSV_FILE = \"TitanicTrainSet.csv\"\n",
    "\n",
    "titanic_data = fetch_data(TITANIC_PATH, CSV_FILE)\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_bad_attributes(df, listOfBadAttributes):\n",
    "    for attribute in listOfBadAttributes:\n",
    "        df = df.drop(attribute, axis = 1)\n",
    "    return df\n",
    "\n",
    "titanic_labels = titanic_data[\"Survived\"]\n",
    "titanic_data = drop_bad_attributes(titanic_data, ['PassengerId','Name', 'Ticket', 'Cabin', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.get_dummies(titanic_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "#class DataFrameSelectorCategorical(BaseEstimator, TransformerMixin):\n",
    "#    def __init__(self, attribute_names):\n",
    "#        self.attribute_names = attribute_names\n",
    "#    def fit(self, X, y=None):\n",
    "#        return self\n",
    "#    def transform(self, X):\n",
    "#        X = X[self.attribute_names].apply(lambda x:pd.factorize(x)[0])\n",
    "#        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
    "cat_attribs = ['Sex_male', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_prepared = full_pipeline.fit_transform(titanic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56573646  0.43279337 -0.47367361 ...,  0.          0.          0.        ]\n",
      " [ 0.66386103  0.43279337 -0.47367361 ...,  1.          0.          1.        ]\n",
      " [-0.25833709 -0.4745452  -0.47367361 ...,  1.          0.          0.        ]\n",
      " ..., \n",
      " [-0.1046374   0.43279337  2.00893337 ...,  1.          0.          0.        ]\n",
      " [-0.25833709 -0.4745452  -0.47367361 ...,  0.          0.          1.        ]\n",
      " [ 0.20276197 -0.4745452  -0.47367361 ...,  0.          1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(titanic_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(titanic_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'weights': ['uniform', 'distance'], 'n_neighbors': [1, 2, 4, 8, 16, 32]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = [{'weights': ['uniform', 'distance'], 'n_neighbors': [1,2,4]}]\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=2, scoring='neg_mean_squared_error', verbose=3)\n",
    "grid_search.fit(titanic_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77441077,  0.78787879,  0.77104377])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(best_knn_clf, titanic_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.68350168,  0.75757576,  0.76430976])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "cross_val_score(sgd_clf, titanic_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spam Not Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "\n",
    "ps = PorterStemmer()\n",
    "spam_dataset = pd.read_csv('datasets/spam/spam.csv', encoding='latin-1')\n",
    "\n",
    "#Get rid of first column it is useless\n",
    "spam_dataset = spam_dataset.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(spam_dataset)):\n",
    "    full_row = ''\n",
    "    stemmed = spam_dataset[\"v2\"][i].translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    stemmed = stemmed.lower()\n",
    "    stemmed = stemmed.split(\" \")\n",
    "    for item in stemmed:\n",
    "        if(item.isdigit()):\n",
    "            item = '0'\n",
    "        item = ps.stem(item)\n",
    "        full_row += item + \" \"\n",
    "    full_row = full_row[:-1]\n",
    "    spam_dataset[\"v2\"][i] = full_row\n",
    "\n",
    "spam_dataset['v1'] = pd.get_dummies(spam_dataset['v1'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri in 0 a wkli comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goe to usf he live around ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go until jurong point crazi avail onli in bugi...\n",
       "1   0                              ok lar joke wif u oni\n",
       "2   1  free entri in 0 a wkli comp to win fa cup fina...\n",
       "3   0        u dun say so earli hor u c alreadi then say\n",
       "4   0  nah i dont think he goe to usf he live around ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#Split the data based on a certain attribute in this case it is spam and ham\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(spam_dataset, spam_dataset[\"v1\"]):\n",
    "    strat_train_set = spam_dataset.loc[train_index]\n",
    "    strat_test_set = spam_dataset.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#vec = CountVectorizer()\n",
    "#data = vec.fit_transform(strat_train_set['v2']).toarray()\n",
    "#print(data)\n",
    "#pipeline = Pipeline([\n",
    "#    ('vectorizer',  CountVectorizer()),\n",
    "#    ('classifier',  MultinomialNB()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "vec = CountVectorizer()\n",
    "data = vec.fit_transform(strat_train_set['v2']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97242771,  0.96835017,  0.97575758])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mnb, X = data, y = strat_train_set['v1'], cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
