{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the MNIST dataset from sklearn.datasets\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Break up the data into attributes and values\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_up(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    top = shifted_image[0,:]\n",
    "    for i in range(0, len(shifted_image)-1):\n",
    "        shifted_image[i,:] = shifted_image[i+1,:]  \n",
    "    shifted_image[27,:] = top\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "\n",
    "def shift_down(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    bottom = shifted_image[27,:]\n",
    "    for i in range(len(shifted_image)-1, 0,-1):\n",
    "        \n",
    "        shifted_image[i,:] = shifted_image[i-1,:]  \n",
    "    shifted_image[0,:] = bottom\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "def shift_left(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    left = shifted_image[:,0]\n",
    "    for i in range(0, len(shifted_image)-1):\n",
    "        shifted_image[:,i] = shifted_image[:,i+1]  \n",
    "    shifted_image[:,27] = left\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "def shift_right(X):\n",
    "    #for number in X:\n",
    "    #    number_image = row.reshape(28,28)\n",
    "    shifted_image = X.reshape(28,28)    \n",
    "    right = shifted_image[:,27]\n",
    "    for i in range(len(shifted_image)-1, 0,-1):\n",
    "        \n",
    "        shifted_image[:,i] = shifted_image[:,i-1]  \n",
    "    shifted_image[:,0] = right\n",
    "    shifted_image = shifted_image.reshape(1,784)\n",
    "    return shifted_image\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(X)):\n",
    "\n",
    "    shifted_image_up = shift_up(X[i].copy())\n",
    "    shifted_image_down = shift_down(X[i].copy())\n",
    "    shifted_image_right = shift_right(X[i].copy())\n",
    "    shifted_image_left = shift_left(X[i].copy())\n",
    "\n",
    "    X = np.vstack((X, shifted_image_up))\n",
    "    X = np.vstack((X, shifted_image_down))\n",
    "    X = np.vstack((X, shifted_image_right))\n",
    "    X = np.vstack((X, shifted_image_left))\n",
    "    \n",
    "    yi = y[i]\n",
    "    \n",
    "    if(i % 1000 == 0):\n",
    "        print(i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    np.append(y, yi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Break the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Shuffle up the data into X_train and y_train so that there is\n",
    "#No order to the values being observed\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'weights': ['uniform', 'distance'], 'n_neighbors': [1,2,4]}]\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
    "           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knn_clf, X = X_train, y = y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Show that the image at row 36000 is the value 5\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000,:]\n",
    "some_digit_image = some_digit.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset\n",
    "\n",
    "\n",
    "# Columns we don't care about\n",
    "PassengerId, Name, Ticket, Cabin\n",
    "\n",
    "# Columns that we need to stratify on\n",
    "Survived\n",
    "\n",
    "# Columns that we do care about\n",
    "Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "# Categorical columns that we care about\n",
    "Survived, Pclass, Sex, Embarked\n",
    "\n",
    "# Numerical columns that we care about\n",
    "Age, SibSp, Parch, Fare\n",
    "\n",
    "# Additional Thoughts\n",
    "Break the classes up into newly made columns representing one for if they were in that class\n",
    "\n",
    "Stratify on survived and died to get an equal distribution on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fetch_data(path, csv_file):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    csv_path = os.path.join(path, csv_file)\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"Titanic\")\n",
    "CSV_FILE = \"TitanicTrainSet.csv\"\n",
    "\n",
    "titanic_data = fetch_data(TITANIC_PATH, CSV_FILE)\n",
    "\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_bad_attributes(df, listOfBadAttributes):\n",
    "    for attribute in listOfBadAttributes:\n",
    "        df = df.drop(attribute, axis = 1)\n",
    "    return df\n",
    "\n",
    "titanic_labels = titanic_data[\"Survived\"]\n",
    "titanic_data = drop_bad_attributes(titanic_data, ['PassengerId','Name', 'Ticket', 'Cabin', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.get_dummies(titanic_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "#class DataFrameSelectorCategorical(BaseEstimator, TransformerMixin):\n",
    "#    def __init__(self, attribute_names):\n",
    "#        self.attribute_names = attribute_names\n",
    "#    def fit(self, X, y=None):\n",
    "#        return self\n",
    "#    def transform(self, X):\n",
    "#        X = X[self.attribute_names].apply(lambda x:pd.factorize(x)[0])\n",
    "#        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\n",
    "cat_attribs = ['Sex_male', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_prepared = full_pipeline.fit_transform(titanic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(titanic_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = [{'weights': ['uniform', 'distance'], 'n_neighbors': [1,2,4]}]\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=2, scoring='neg_mean_squared_error', verbose=3)\n",
    "grid_search.fit(titanic_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(best_knn_clf, titanic_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "cross_val_score(sgd_clf, titanic_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spam Not Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "\n",
    "ps = PorterStemmer()\n",
    "spam_dataset = pd.read_csv('datasets/spam/spam.csv', encoding='latin-1')\n",
    "\n",
    "#Get rid of first column it is useless\n",
    "spam_dataset = spam_dataset.iloc[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(spam_dataset)):\n",
    "    full_row = ''\n",
    "    stemmed = spam_dataset[\"v2\"][i].translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    stemmed = stemmed.lower()\n",
    "    stemmed = stemmed.split(\" \")\n",
    "    for item in stemmed:\n",
    "        if(item.isdigit()):\n",
    "            item = '0'\n",
    "        item = ps.stem(item)\n",
    "        full_row += item + \" \"\n",
    "    full_row = full_row[:-1]\n",
    "    spam_dataset[\"v2\"][i] = full_row\n",
    "\n",
    "spam_dataset['v1'] = pd.get_dummies(spam_dataset['v1'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri in 0 a wkli comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goe to usf he live around ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  go until jurong point crazi avail onli in bugi...\n",
       "1   0                              ok lar joke wif u oni\n",
       "2   1  free entri in 0 a wkli comp to win fa cup fina...\n",
       "3   0        u dun say so earli hor u c alreadi then say\n",
       "4   0  nah i dont think he goe to usf he live around ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#Split the data based on a certain attribute in this case it is spam and ham\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(spam_dataset, spam_dataset[\"v1\"]):\n",
    "    strat_train_set = spam_dataset.loc[train_index]\n",
    "    strat_test_set = spam_dataset.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "vec = CountVectorizer()\n",
    "data = vec.fit_transform(strat_train_set['v2']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97242771,  0.96835017,  0.97575758])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mnb, X = data, y = strat_train_set['v1'], cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
